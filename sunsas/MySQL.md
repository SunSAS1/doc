# 3.1 MySQL基础

> 作者：SunSAS
>
> **介绍：** SunSAS是SunSAS


## 3.1.1 MySQL架构

### 架构介绍
![MySQL架构](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/640.png)

MySQL大致分为4个层。
- **连接层**：最上层是一些客户端和连接服务。主要完成一些类似于连接处理、授权认证、及相关的安全方案。在该层上引入了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于SSL的安全链接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。
- **服务层**：第二层服务层，主要完成大部分的核心服务功能， 包括查询解析、分析、优化、缓存、以及所有的内置函数，所有跨存储引擎的功能也都在这一层实现，包括触发器、存储过程、视图等。
- **引擎层**：第三层存储引擎层，存储引擎真正的负责了MySQL中数据的存储和提取，服务器通过API与存储引擎进行通信。不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需要进行选取。
- **存储层**：第四层为数据存储层，主要是将数据存储在运行于该设备的文件系统之上，并完成与存储引擎的交互。


MySQL的一个优势就在于存储引擎的架构上，**插件式的存储引擎架构将查询处理和其它的系统任务以及数据的存储提取相分离**。这种架构可以根据业务的需求和实际需要选择合适的存储引擎。

对于上图各组件介绍：
1. **Connectors**：是MySQL向外提供的交互组件，如java,.net,php等语言可以通过该组件来操作SQL语句，实现与SQL的交互。
2. **Service & Utilities**：管理服务组件和工具组件， 提供对MySQL的集成管理，如备份(Backup),恢复(Recovery),安全管理(Security)等。
3. **Connection Pool** ：连接池组件，负责监听对客户端向MySQL Server端的各种请求，接收请求，转发请求到目标模块。每个成功连接MySQL Server的客户请求都会被
创建或分配一个线程，该线程负责客户端与MySQL Server端的通信，接收客户端发送的命令，传递服务端的结果信息等。
4. **SQL Interface**:SQL接口组件,接收用户SQL命令，如DML,DDL和存储过程等，并将最终结果返回给用户。
5. **Parser**:查询分析器组件,首先分析SQL命令语法的合法性，并尝试将SQL命令分解成数据结构，若分解失败，则提示SQL语句不合理。
6. **Optimizer**:优化器组件,对SQL命令按照标准流程进行优化分析。
7. **Caches**:缓存。
8. **Pluggable Storage Engines**：存储引擎，这个下次再说。
9. **File System**：存储层。

### MySQl如何执行一条sql语句？

![MySQl如何执行一条sql语句](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/MySQl%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E4%B8%80%E6%9D%A1sql%E8%AF%AD%E5%8F%A5.png)
图：极客时间。

注意**MySQL 8.0 版本开始直接将查询缓存的整块功能删掉了**。


> 参考：
>
> [有了这份MySQL精华总结，和面试官扯半天都没问题](https://mp.weixin.qq.com/s/H-lAqN5918vixP95BWGmIQ)  
> [浅谈MySQL架构体系](https://www.cnblogs.com/wangjiming/p/10410904.html)





---



## 3.1.2 MySQL存储引擎
使用哪一种引擎可以灵活选择，**一个数据库中多个表可以使用不同引擎**以满足各种性能和实际需求，使用合适的存储引擎，将会提高整个数据库的性能 。

MySQL服务器使用可插拔的存储引擎体系结构，可以从运行中的 MySQL 服务器加载或卸载存储引擎 。

使用`show engine;`命令查看MySQL支持的引擎。

![MySQL支持的引擎](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/mysql%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E.png)

这里是MySQL5.7版本，可见现在默认引擎是InnoDB。


```mysql
--准确查看某个数据库中的某一表所使用的存储引擎
show table status like 'tablename'
show table status from database where name="tablename"
-- 修改存储引擎
ALTER TABLE t ENGINE = InnoDB;
-- 修改默认存储引擎，也可以在配置文件my.cnf中修改默认引擎
SET default_storage_engine=NDBCLUSTER;
```

这里只介绍几种常见的引擎。

### MyISAM
在MySQL5.5之前，MyISAM是**默认数据库引擎**。虽然性能极佳，⽽且提供了⼤量的特性，包括全⽂索
引、压缩、空间函数等，但MyISAM**不⽀持事务和⾏级锁**，⽽且最⼤的缺陷就是崩溃后⽆法安全恢复。

### InnoDB
5.5版本之后，MySQL引⼊了InnoDB（事务性数据库引擎），对比MyISAM引擎，写的处理效率会差一些，并且会占用更多的磁盘空间以保留数据和索引。 
InnoDB存储引擎的特点：支持自动增长列，支持外键约束。
不过《MySQL高性能》如此说：
> 不要轻易相信“MyISAM⽐InnoDB快”之类的经验之谈，这个结论往往不是绝对的。在很多我们已知场
景中，InnoDB的速度都可以让MyISAM望尘莫及，尤其是⽤到了聚簇索引，或者需要访问的数据都可
以放⼊内存的应⽤。

### MEMOEY

Memory存储引擎使用存在于内存中的内容来创建表。每个memory表只实际对应一个磁盘文件，格式是.frm。memory类型的表访问非常的快，因为它的数据是放在**内存**中的，并且默认使用HASH索引，但是一旦服务关闭，表中的数据就会丢失掉。 
MEMORY存储引擎的表可以选择使用BTREE索引或者HASH索引，两种不同类型的索引有其不同的使用范围 

Hash索引优点：  
Hash 索引结构的特殊性，其检索效率非常高，索引的检索可以一次定位，不像B-Tree 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问，所以 Hash 索引的查询效率要远高于 B-Tree 索引。 

Hash索引缺点： 那么不精确查找呢，也很明显，因为hash算法是基于等值计算的，所以对于“like”等范围查找hash索引无效，不支持；

Memory类型的存储引擎主要用于哪些内容变化不频繁的代码表，或者作为统计操作的中间结果表，便于高效地对中间结果进行分析并得到最终的统计结果，。对存储引擎为memory的表进行更新操作要谨慎，因为数据并没有实际写入到磁盘中，所以一定要对下次重新启动服务后如何获得这些修改后的数据有所考虑。

### InnoDB与MyISAM对比


对比项 | MyISAM	| InnoDB
---|---|---
主外键	| 不支持	| 支持
事务	| 不支持	| 支持
行表锁	| 表锁，即使操作一条记录也会锁住整个表，不适合高并发的操作 |	行锁,操作时只锁某一行，不对其它行有影响，适合高并发的操作
缓存	| 只缓存索引，不缓存真实数据	| 不仅缓存索引还要缓存真实数据，对内存要求较高，而且内存大小对性能有决定性的影响
表空间	| 小	| 大
关注点	| 性能	| 事务
默认安装	| 是	| 是

1. InnoDB支持事务，MyISAM不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；
2. InnoDB 支持外键，而 MyISAM 不支持。
3. InnoDB 是**聚簇索引**，MyISAM 是**非聚簇索引**（索引文件与数据文件分离，这样的索引称为"非聚簇索引"）。聚簇索引的文件存放在主键索引的叶子节点上，因此 **InnoDB 必须要有主键**，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。
4. InnoDB 不保存表的具体行数，执行select count(*) from table 时需要全表扫描。而 MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快；
5. **InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁**。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的又一个重要原因；


#### 适用场景
- MyISAM管理非事务表。它提供高速存储和检索，以及全文搜索能力。如果应用中需要执行**大量的SELECT**查询，那么MyISAM是更好的选择。
- InnoDB用于事务处理应用程序，具有众多特性，包括ACID事务支持。如果应用中需要执行大量的INSERT或UPDATE操作，则应该使用InnoDB，这样可以提高多用户并发操作的性能。

在大数据量，高并发量的互联网业务场景下，请使用InnoDB:
- **行锁**，对提高并发帮助很大
- **事务**，对数据一致性帮助很大
而这两个是InnoDB所特有的。

> 参考
>
> [MySQL中四种常用存储引擎的介绍](https://blog.csdn.net/qq_27028821/java/article/details/52267991)   
> [MyISAM和InnoDB区别和应用场景](https://www.jianshu.com/p/dc60346d55a2)


---


## 3.1.3 MySQL索引

### 介绍
MySQL官方对索引的定义为：**索引（Index）是帮助MySQL高效获取数据的数据结构**，所以说索引的本质是：数据结构。

可以简单的理解为“排好序的快速查找数据结构”，数据本身之外，数据库还维护者一个满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。下图是一种可能的索引方式示例:  
![索引方式示例](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/%E7%B4%A2%E5%BC%95%E7%A4%BA%E4%BE%8B.png)

排序二叉树查找自然比线性快，时间复杂度O(logn)。当然这只是示例，MySQL使用的B+树。
> 平常说的索引，没有特别指明的话，就是B+树（多路搜索树，不一定是二叉树）结构组织的索引。其中聚集索引，次要索引，覆盖索引，符合索引，前缀索引，唯一索引默认都是使用B+树索引，统称索引。此外还有哈希索引等。

> 索引本身也很大，不可能全部存储在内存中，一般以索引文件的形式存储在磁盘上

**优势**

提高数据检索效率，降低数据库IO成本；  
降低数据排序的成本，降低CPU的消耗。

**劣势**

索引也是一张表，保存了主键和索引字段，并指向实体表的记录，所以也需要占用内存；  
虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件每次更新添加了索引列的字段， 都会调整因为更新所带来的键值变化后的索引信息。

### 基本语法

```
-- 创建索引
CREATE [UNIQUE] INDEX indexName ON mytable(username(length));
-- 添加索引
ALTER table tableName ADD [UNIQUE] INDEX indexName(columnName);
-- 删除
DROP INDEX [indexName] ON mytable;
-- 查看
SHOW INDEX FROM table_name\G

--这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）。该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL。
ALTER TABLE tbl_name ADD PRIMARY KEY (column_list): 
-- 这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）。
ALTER TABLE tbl_name ADD UNIQUE index_name (column_list 
-- 添加普通索引，索引值可出现多次。
ALTER TABLE tbl_name ADD INDEX index_name (column_list) 
-- (column_list)该语句指定了索引为 FULLTEXT ，用于全文索引。
ALTER TABLE tbl_name ADD FULLTEXT index_name 
```

### 索引分类
**数据结构角度**
- B+Tree索引
- Hash索引
- Full-Text全文索引
- R-Tree索引

**逻辑分类**
- 主键索引
- 普通索引（单列索引），每个索引只包含单个列，一个表可以有多个单列索引
- 联合索引（多列索引）复合索引指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用复合索引时遵循最左前缀集合
- 唯一索引
- 空间索引：空间索引是对空间数据类型的字段建立的索引，MYSQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING、POLYGON。MYSQL使用SPATIAL关键字进行扩展，使得能够用于创建正规索引类型的语法创建空间索引。创建空间索引的列，必须将其声明为NOT NULL，**空间索引只能在存储引擎为MYISAM的表中创建**。

**物理存储角度**
- 聚集索引
- 非聚集索引，也叫辅助索引

区别：

1. 聚集索引在叶子节点存储的是表中的数据
2. 非聚集索引在叶子节点存储的是主键和索引列
3. 使用非聚集索引查询出数据时，拿到叶子上的主键再去查到想要查找的数据。(拿到主键再查找这个过程叫做**回表**)



### 基本存储结构
MySQL的基本存储结构是**页**(记录都存在页里边)：  
![页](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/164c6d7a53a7920b.png)

页是其磁盘管理的最小单位。InnoDB 存储引擎中默认每个页的大小为16KB，可通过参数 innodb_page_size 将页的大小设置为 4K、8K、16K，在 MySQL 中可通过如下命令查看页的大小：`show variables like 'innodb_page_size';`  
![页2](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/164c6d7a53b78847.png)

- 各个数据页可以组成一个**双向链表**。
- 而**每个数据页中的记录又可以组成一个单向链表** 。
- 每个数据页都会为存储在它里边儿的记录生成一个页目录，在通过主键查找某条记录的时候可以在页目录中使用二分法快速定位到对应的槽，然后再遍历该槽对应分组中的记录即可快速找到指定的记录。
- 以其他列(非主键)作为搜索条件：**只能从最小记录**开始依次遍历单链表中的每条记录。


### B-Tree
注意B树就是B-树，把他称之为“B减树”是不正确的，他就是一个横杠而已。  
B-Tree 结构的数据可以让系统高效的找到数据所在的磁盘块。为了描述 B-Tree，首先定义一条记录为一个二元组[key, data] ，key为记录的键值，对应表中的主键值，data 为一行记录中除主键外的数据。对于不同的记录，key值互不相同。
一棵m阶的B-Tree有如下特性：
1. 每个节点最多有m个孩子
2. 除了根节点和叶子节点外，其它每个节点至少有Ceil(m/2)个孩子。
3. 若根节点不是叶子节点，则至少有2个孩子
4. 所有叶子节点都在同一层，且不包含其它关键字信息
5. 每个非终端节点包含n个关键字信息（P0,P1,…Pn, k1,…kn）
6. 关键字的个数n满足：ceil(m/2)-1 <= n <= m-1
7. ki(i=1,…n)为关键字，且关键字升序排序
8. Pi(i=1,…n)为指向子树根节点的指针。
9. P(i-1)指向的子树的所有节点关键字均小于ki，但都大于k(i-1)

一个3阶的B-Tree：  
![B-Tree](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/B-Tree.png)

![B-Tree](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/B-Tree4.JPG)

类似排序二叉树，要求父节点值比左节点的都大，比右节点的都小。  
每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的关键字（例如一层的17，35）和三个指向子树根节点的指针（p1,p2,p3），指针存储的是子节点所在磁盘块的地址。由定义可知根节点中p1指向的范围应该小于17，P2指针指向的子树的数据范围为17~35，P3指针指向的子树的数据范围为大于35。

查找关键字29的过程：
1. 根据根节点找到磁盘块1，读入内存。【磁盘I/O操作第1次】
2. 比较关键字29在区间（17,35），找到磁盘块1的指针P2。
3. 根据P2指针找到磁盘块3，读入内存。【磁盘I/O操作第2次】
4. 比较关键字29在区间（26,30），找到磁盘块3的指针P2。
5. 根据P2指针找到磁盘块8，读入内存。【磁盘I/O操作第3次】
6. 在磁盘块8中的关键字列表中找到关键字29。

分析上面过程，发现需要3次磁盘I/O操作，和3次内存查找操作。由于内存中的关键字是一个有序表结构，可以利用二分法查找提高效率。而3次磁盘**I/O操作是影响整个B-Tree查找效率的决定因素**。B-Tree相对于AVLTree缩减了节点个数，使每次磁盘I/O取到内存的数据都发挥了作用，从而提高了查询效率。

### B+Tree
B+Tree 是在 B-Tree 基础上的一种优化，使其更适合实现外存储索引结构,InnoDB 存储引擎是用 B+Tree 实现其索引结构。
由于B-Tree每个节点中不仅包含数据的key值，还有data值。而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小，当存储的数据量很大时同样会**导致B-Tree的深度较大**，增大查询时的磁盘I/O次数，进而影响查询效率。B+Tree的不同是**所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储key值信息**。这样就可以大大加大每个节点存储的key值数量，降低B+Tree的高度。
1. 非叶子节点只存储键值信息；
2. **所有叶子节点之间都有一个链指针**；
3. 数据记录都存放在叶子节点中。


由于B+Tree的非叶子节点只存储键值信息，假设每个磁盘块能存储4个键值及指针信息，则变成B+Tree后其结构如下图所示：  
![B+Tree](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/B%2BTree.png)

![B+Tree](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/B%2Btree5.JPG)

B+树的头指针有两个，一个指向根节点，另一个指向关键字最小的元素(上图DATA)，因此B+树有两种遍历的方式：
1. 从根节点开始随机查询
2. 从最小关键词顺序查询

InnoDB存储引擎中页的大小为16KB，一般表的主键类型为INT（占用4个字节）或BIGINT（占用8个字节），指针类型也一般为4或8个字节，也就是说一个页（B+Tree中的一个节点）中大概存储16KB/(8B+8B)=1K个键值（因为是估值，为方便计算，这里的K取值为10^3 ）。也就是说一个深度为3的B+Tree索引可以维护10^3 * 10^3 * 10^3 = 10亿 条记录。

实际情况中每个节点可能不能填充满，因此在数据库中，B+Tree的高度一般都在2-4层。MySQL的InnoDB存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要1~3次磁盘I/O操作。

当b+树的数据项是复合的数据结构，比如(name,age,sex)的时候，**b+数是按照从左到右的顺序来建立搜索树**的，比如当(张三,20,F)这样的数据来检索的时候，b+树会优先比较name来确定下一步的所搜方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20,F)这样的没有name的数据来的时候，b+树就不知道下一步该查哪个节点，因为建立搜索树的时候name就是第一个比较因子，必须要先根据name来搜索才能知道下一步去哪里查询。比如当(张三,F)这样的数据来检索时，b+树可以用name来指定搜索方向，但下一个字段age的缺失，所以只能把名字等于张三的数据都找到，然后再匹配性别是F的数据了， 这个是非常重要的性质，即**索引的最左匹配特性**。

> **为什么Mysql索引要用B+树不是B树**？
> 
> 用B+树不用B树考虑的是IO对性能的影响，B树的每个节点都存储数据，而B+树只有叶子节点才存储数据，所以查找相同数据量的情况下，B树的高度更高，IO更频繁。数据库索引是存储在磁盘上的，当数据量大时，就不能把整个索引全部加载到内存了，只能逐一加载每一个磁盘页（对应索引树的节点）。其中在MySQL底层对B+树进行进一步优化：在叶子节点中是双向链表，且在链表的头结点和尾节点也是循环指向的。

还有一个**B*树**：
B*树：在B+树基础上，为非叶子结点也增加链表指针，将结点的最低利用率从1/2提高到2/3。 
![B星树](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/BxingTree6.JPG)

### 主键索引与辅助索引
#### MyISAM
MyISAM引擎的索引文件和数据文件是分离的。MyISAM引擎索引结构的叶子节点的数据域，存放的并不是实际的数据记录，而是数据记录的地址。**索引文件与数据文件分离，这样的索引称为"非聚簇索引"**。MyISAM的主索引与辅助索引区别并不大，只是主键索引不能有重复的关键字。

![MyISAM](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/MyISAM%E7%B4%A2%E5%BC%95.png)

在MyISAM中，索引（含叶子节点）存放在单独的.myi文件中，叶子节点存放的是数据的物理地址偏移量（通过偏移量访问就是随机访问，速度很快）。

主索引是指主键索引，键值不可能重复；辅助索引则是普通索引，键值可能重复。

通过索引查找数据的流程：先从索引文件中查找到索引节点，从中拿到数据的文件指针，再到数据文件中通过文件指针定位了具体的数据（回表）。辅助索引类似。

#### InnoDB

InnoDB引擎索引结构的叶子节点的数据域，存放的就是实际的数据记录（对于主索引，此处会存放表中所有的数据记录；对于辅助索引此处会引用主键，检索的时候通过主键到主键索引中找到对应数据行），或者说，**InnoDB的数据文件本身就是主键索引文件，这样的索引被称为“聚簇索引”，一个表只能有一个聚簇索引。**

**主键索引**

InnoDB索引是**聚集索引**，它的索引和数据是存入同一个.idb文件中的，因此它的索引结构是在同一个树节点中同时存放索引和数据，如下图中最底层的叶子节点有三行数据，对应于数据表中的id、stu_id、name数据项。  
![InnoDB](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/InnoDB%E7%B4%A2%E5%BC%95.png)

**辅助（非主键）索引**

我们以示例中学生表中的name列建立辅助索引，它的索引结构跟主键索引的结构有很大差别，在最底层的叶子结点有两行数据，第一行的字符串是辅助索引，按照ASCII码进行排序，第二行的整数是主键的值。

这就意味着，对name列进行条件搜索，需要两个步骤：

① 在辅助索引上检索name，到达其叶子节点获取对应的主键；

② 使用主键在主索引上再进行对应的检索操作。

这也就是所谓的“**回表查询**”

![辅助（非主键）索引](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/InnoDB%E9%9D%9E%E4%B8%BB%E9%94%AE%E7%B4%A2%E5%BC%95.png)

InnoDB 存储结构，索引与数据是共同存储的，不管是主键索引还是辅助索引，在查找时都是通过先查找到索引节点才能拿到相对应的数据，如果我们在设计表结构时没有显式指定索引列的话，MySQL 会从表中选择数据不重复的列建立索引，如果没有符合的列，则 MySQL 自动为 InnoDB 表**生成一个隐含字段作为主键**，并且这个字段长度为6个字节，类型为整型。

> **为什么推荐使用整型自增主键而不是选择UUID？**  
> 1.  UUID是字符串，比整型消耗更多的存储空间;  
> 2. 在B+树中进行查找时需要跟经过的节点值比较大小，整型数据的比较运算比字符串更快速；
> 3. 自增的整型索引在磁盘中会连续存储，在读取一页数据时也是连续；UUID是随机产生的，读取的上下两行数据存储是分散的，不适合执行where id > 5 && id < 20的条件查询语句。
> 4. 在插入或删除数据时，整型自增主键会在叶子结点的末尾建立新的叶子节点，不会破坏左侧子树的结构；UUID主键很容易出现这样的情况，B+树为了维持自身的特性，有可能会进行结构的重构，消耗更多的时间。
    
> **为什么非主键索引结构叶子节点存储的是主键值？**
>
> 保证数据一致性和节省存储空间，可以这么理解：商城系统订单表会存储一个用户ID作为关联外键，而不推荐存储完整的用户信息，因为当我们用户表中的信息（真实名称、手机号、收货地址···）修改后，不需要再次维护订单表的用户数据，同时也节省了存储空间。

### 聚簇索引与非聚簇索引
上面说过InnoDB使用的**聚簇索引**（节点中同时存放索引和数据），而MyISAM使用的**非聚簇索引**（MyISAM引擎索引结构的叶子节点的数据域，存放的并不是实际的数据记录，而是数据记录的地址）

![辅助（非主键）索引](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/20201012/2f67547e0caa0d1ea9bc7cb53966eedf70d49db3.png)

看上去聚簇索引的效率明显要低于非聚簇索引，因为每次使用辅助索引检索都要经过两次B+树查找，这不是多此一举吗？

#### 聚簇索引优势
**为什么要使用聚簇索引？**

- 由于行数据和叶子节点存储在一起，同一页中会有多条行数据，访问同一数据页不同行记录时，已经把页加载到了Buffer中，再次访问的时候，会**在内存中完成访问，不必访问磁盘**。这样主键和行数据是一起被载入内存的，找到叶子节点就可以立刻将行数据返回了，如果按照主键Id来组织数据，获得数据更快。
- 辅助索引使用主键作为"指针"而不是使用地址值作为指针的好处是，减少了当出现行移动或者数据页分裂时辅助索引的维护工作，使用主键值当作指针会让辅助索引占用更多的空间，换来的好处是InnoDB在移动行时无须更新辅助索引中的这个"指针"。也就是说行的位置（实现中通过16K的Page来定位）会随着数据库里数据的修改而发生变化（前面的B+树节点分裂以及Page的分裂），使用聚簇索引就可以保证不管这个主键B+树的节点如何变化，辅助索引树都不受影响。
- 聚簇索引适合用在排序的场合，非聚簇索引不适合
- 取出一定范围数据的时候，用聚簇索引
- 二级索引需要两次索引查找，而不是一次才能取到数据，因为存储引擎第一次需要通过二级索引找到索引的叶子节点，从而找到数据的主键，然后在聚簇索引中用主键再次查找索引，再找到数据
- 可以把相关数据保存在一起。例如实现电子邮箱时，可以根据用户 ID 来聚集数据，这样只需要从磁盘读取少数的数据页就能获取某个用户的全部邮件。如果没有使用聚簇索引，则每封邮件都可能导致一次磁盘 I/O。

#### 聚簇索引劣势
- 维护索引很昂贵，特别是插入新行或者主键被更新导至要分页(page split)的时候。建议在大量插入新行后，选在负载较低的时间段，通过OPTIMIZE TABLE优化表，因为必须被移动的行数据可能造成碎片。使用独享表空间可以弱化碎片
- 表如果UUId（随机ID）作为主键，使数据存储稀疏，这就会出现聚簇索引有可能有比全表扫面更慢，所以建议auto_increment
- 如果主键比较大的话，那辅助索引将会变的更大，因为辅助索引的叶子存储的是主键值；过长的主键值，会导致非叶子节点占用占用更多的物理空间

### Hash索引
主要就是通过Hash算法（常见的Hash算法有直接定址法、平方取中法、折叠法、除数取余法、随机数法），将数据库字段数据转换成定长的Hash值，与这条数据的行指针一并存入Hash表的对应位置；如果发生Hash碰撞（两个不同关键字的Hash值相同），则在对应Hash键下以链表形式存储。  
![Hash索引](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/Hash%E7%B4%A2%E5%BC%95.jpg)

检索算法：在检索查询时，就再次对待查关键字再次执行相同的Hash算法，得到Hash值，到对应Hash表对应位置取出数据即可，如果发生Hash碰撞，则需要在取值时进行筛选。目前使用Hash索引的数据库并不多，主要有**Memory**等。

**劣势：**

- 哈希索引也没办法利用索引完成**排序**
- 不支持**最左匹配原则**
- 在有大量重复键值情况下，哈希索引的效率也是极低的---->哈希碰撞问题。
- 不支持**范围查询**

> **为何不采用Hash方式？**
>
> 因为Hash索引底层是哈希表，哈希表是一种以key-value存储数据的结构，所以多个数据在存储关系上是完全没有任何顺序关系的，所以，对于区间查询是无法直接通过索引查询的，就需要全表扫描。所以，哈希索引只适用于等值查询的场景。而B+ Tree是一种多路平衡查询树，所以他的节点是天然有序的（左子节点小于父节点、父节点小于右子节点），所以对于范围查询的时候不需要做全表扫描。
>
> 哈希索引不支持多列联合索引的最左匹配规则，如果有大量重复键值得情况下，哈希索引的效率会很低，因为存在哈希碰撞问题。

MySQL目前有Memory引擎和NDB引擎支持Hash索引。
**InnoDB是自适应哈希索引**的（hash索引的创建由InnoDB存储引擎引擎自动优化创建，我们干预不了）


### full-text全文索引
全文索引也是MyISAM的一种特殊索引类型，主要用于全文索引，InnoDB从MYSQL5.6版本提供对全文索引的支持。

它用于替代效率较低的**LIKE模糊匹配**操作，而且可以通过多字段组合的全文索引一次性全模糊匹配多个字段。

同样使用B-Tree存放索引数据，但使用的是特定的算法，将字段数据分割后再进行索引（一般每4个字节一次分割），索引文件存储的是分割前的索引字符串集合，与分割后的索引信息，对应Btree结构的节点存储的是分割后的词信息以及它在分割前的索引字符串集合中的位置。


### R-Tree空间索引
空间索引是MyISAM的一种特殊索引类型，主要用于地理空间数据类型


### 常见问题
**哪些情况需要创建索引**
- 主键自动建立唯一索引
- 频繁作为查询条件的字段
- 查询中与其他表关联的字段，外键关系建立索引
- 单键/组合索引的选择问题，高并发下倾向创建组合索引
- 查询中排序的字段，排序字段通过索引访问大幅提高排序速度
- 查询中统计或分组字段

**哪些情况不需要创建索引**
- 表记录太少
- 经常增删改的表
- 数据重复且分布均匀的表字段，只应该为最经常查询和最经常排序的数据列建立索引（如果某个数据类包含太多的重复数据，建立索引没有太大意义）
- 频繁更新的字段不适合创建索引（会加重IO负担）
- where条件里用不到的字段不创建索引


**MySQL高效索引**

**覆盖索引**（Covering Index）,或者叫索引覆盖， 也就是平时所说的不需要**回表**操作。
一个索引包含（覆盖）满足查询结果的数据就叫做覆盖索引。  
就是select的数据列只用从索引中就能够取得，不必读取数据行，MySQL可以利用索引返回select列表中的字段，而不必根据索引再次读取数据文件，换句话说查询列要被所建的索引覆盖。  
譬如：现在我创建了索引(username,age)，在查询数据的时候：select username , age from user where username = 'Java3y' and age = 20。
很明显地知道，我们上边的查询是走索引的，并且，要查询出的列在叶子节点都存在！所以，就不用回表了。

**索引最左匹配原则**

索引可以简单如一个列(a)，也可以复杂如多个列(a, b, c, d)，即联合索引。
如果是联合索引，那么key也由多个列组成，同时，索引只能用于查找key是否存在（相等），**遇到范围查询**(>、<、between、like左匹配)等就不能进一步匹配了，后续退化为**线性查找**。
> 如有索引(a, b, c, d)，查询条件a = 1 and b = 2 and c > 3 and d = 4，则会在每个节点依次命中a、b、c，无法命中d。(很简单：索引命中只能是相等的情况，不能是范围匹配)

因此，列的排列顺序决定了可命中索引的列数。

**注意事项**
1. **最左前缀匹配原则**。这是非常重要、非常重要、非常重要（重要的事情说三遍）的原则，MySQL会一直向右匹配直到遇到范围查询（>,<,BETWEEN,LIKE）就停止匹配。
2. 尽量选择**区分度高**的列作为索引，区分度的公式是 COUNT(DISTINCT col) / COUNT(*)。表示字段不重复的比率，比率越大我们扫描的记录数就越少。
3. **索引列不能参与计算**，尽量保持列“干净”。比如，FROM_UNIXTIME(create_time) = '2016-06-06' 就不能使用索引，原因很简单，B+树中存储的都是数据表中的字段值，但是进行检索时，需要把所有元素都应用函数才能比较，显然这样的代价太大。所以语句要写成 ： create_time = UNIX_TIMESTAMP('2016-06-06')。
4. 尽可能的**扩展索引**，不要新建立索引。比如表中已经有了a的索引，现在要加（a,b）的索引，那么只需要修改原来的索引即可。
5. 单个多列组合索引和多个单列索引的检索查询效果不同，因为在执行SQL时，MySQL**只能使用一个索引**，会从多个单列索引中选择一个限制最为严格的索引。


> 参考：
>
> [有了这份MySQL精华总结，和面试官扯半天都没问题！ ](https://mp.weixin.qq.com/s/H-lAqN5918vixP95BWGmIQ)
>
>[数据库两大神器【索引和锁】](https://juejin.im/post/5b55b842f265da0f9e589e79)
>
> [B树、B-树、B+树与红黑树](https://blog.csdn.net/qq_17612199/article/details/50944413?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase)
> 
> [聚簇索引与非聚簇索引（也叫二级索引）](https://www.jianshu.com/p/fa8192853184)


---


## 3.1.4 MySQL查询

### SQL执行顺序
手写的语句：

```
SELECT DISTINCT <select_list>
FROM  <left_table> <join_type>
JOIN  <right_table> ON <join_condition>
WHERE  <where_condition>
GROUP BY  <group_by_list>
HAVING <having_condition>
ORDER BY <order_by_condition>
LIMIT <limit_number>
```
机读：

```
FROM  <left_table>
ON <join_condition>
<join_type> JOIN  <right_table>
WHERE  <where_condition>
GROUP BY  <group_by_list>
HAVING <having_condition>
SELECT
DISTINCT <select_list>
ORDER BY <order_by_condition>
LIMIT <limit_number>
```
![总结](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/MySQL%E6%9C%BA%E8%AF%BB.png)

### count(*) 和 count(1)和count(列名)区别

**执行效果上**：

- count(*)包括了所有的列，相当于行数，在统计结果的时候，不会忽略列值为NULL
- count(1)包括了所有列，用1代表代码行，在统计结果的时候，不会忽略列值为NULL
- count(列名)只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数，即某个字段值为NULL时，不统计。

**执行效率上**：

- 列名为主键，count(列名)会比count(1)快
- 列名不为主键，count(1)会比count(列名)快
- 如果表多个列并且没有主键，则 count(1) 的执行效率优于 count(*)
- 如果有主键，则 select count（主键）的执行效率是最优的
- 如果表只有一个字段，则 select count(*) 最优。


### MySQL中 in和 exists 的区别？
**exists**：exists对外表用loop逐条查询，每次查询都会查看exists的条件语句，当exists里的条件语句能够返回记录行时（无论记录行是的多少，只要能返回），条件就为真，返回当前loop到的这条记录；反之，如果exists里的条件语句不能返回记录行，则当前loop到的这条记录被丢弃，exists的条件就像一个bool条件，当能返回结果集则为true，不能返回结果集则为false

**in**：in查询相当于多个or条件的叠加。
#### IN查询分析
一下A代表外表，B代表子查询表。
```
SELECT * FROM A WHERE id IN (SELECT id FROM B);
-- 等价于：
1、SELECT id FROM B ----->先执行in中的查询
2、SELECT * FROM A WHERE A.id = B.id
```
以上in()中的查询只执行一次，它查询出B中的所有的id并**缓存**起来，然后检查A表中查询出的id在缓存中是否存在，如果存在则将A的查询数据加入到结果集中，直到遍历完A表中所有的结果集为止。
> 1、A表中有100条记录，B表中有1000条记录，那么最多可能遍历100*1000次，效率很差
>
> 2、A表中有1000条记录，B表中有100条记录，那么最多可遍历1000*100次，区别就是内循环次数减少，因为是外循环与内循环比较，如果相同就返回，效率大大提升。

结论：**IN()查询适合B表数据比A表数据小的情况，IN()查询是从缓存中取数据。**

#### EXISTS查询分析
```
SELECT * FROM A WHERE EXISTS(SELECT 1 FROM b WHERE B.id = A.id);
-- 以上查询等价于：
1、SELECT * FROM A;
2、SELECT I FROM B WHERE B.id = A.id;
```
> 查看是否有记录，一般是作条件用的。select 1 from 中的1是一常量，查到的所有行的值都是它，但从效率上来说，1>anycol>*，因为不用查字典表。

使用exists关键字进行查询的时候，首先，我们先查询的不是子查询的内容，而是查我们的主查询的表.

会先执行`SELECT * FROM A`查询，执行A.length次，并不会将EXISTS()查询结果结果进行缓存，因为EXISTS()查询返回一个布尔值true或flase，它只在乎EXISTS()的查询中是否有记录，与具体的结果集无关。

EXISTS()查询是将主查询的结果集放到子查询中做验证，根据验证结果是true或false来决定主查询数据结果是否得以保存。
> 1.A表有100条记录,B表有10000条记录,那么EXISTS()会执行100次去判断A表中的id是否与B表中的id相等.因为它只执行A.length次，可见B表数据越多,越适合EXISTS()发挥效果.
> 
> 2.A表有10000条记录,B表有100条记录,那么EXISTS()还是执行10000次,此时不如使用in()遍历10000*100次,**因为IN()是在内存里遍历数据进行比较**,而EXISTS()需要查询数据库,我们都知道查询数据库所消耗的性能更高,而内存比较很快.

#### 结论
如果查询的两个表**大小相当**，那么用in和exists差别不大。

如果两个表中一个较小，一个是大表，则**子查询表大的用exists，子查询表小的用in**。
```
SELECT * FROM A WHERE A.id IN (SELECT id FROM B);
SELECT * FROM A WHERE EXISTS (SELECT * from B WHERE B.id = A.id);
```
A小表，B大表
```
-- 效率低，用到了A表上cc列的索引；
select * from A where cc in(select cc from B)　
-- 效率高，用到了B表上cc列的索引。
select * from A where exists(select cc from B where cc=A.cc)　　
```
A大表，B小表

```
-- 效率高，用到了B表上cc列的索引
select * from B where cc in(select cc from A)
-- 效率低，用到了A表上cc列的索引
select * from B where exists(select cc from A where cc=B.cc)
```
### not in和 not exists 
如果查询语句使用了not in，那么对内外表都进行全表扫描，**没有用到索引**；而not exists的子查询依然能用到表上的索引。所以无论哪个表大，用not exists都比not in 要快。  
所以，请**尽量不要使用not in**(它会调用子查询)，而尽量使用not exists（它会调用关联子查询）。如果子查询中返回的任意一条记录**含有空值，则查询将不返回任何记录**。如果子查询字段有非空限制，这时可以使用not in，并且可以通过提示让它用hasg_aj或merge_aj连接。


```
1 create table #t1(c1 int,c2 int);
2 create table #t2(c1 int,c2 int);
3 insert into #t1 values(1,2);
4 insert into #t1 values(1,3);
5 insert into #t2 values(1,2);
6 insert into #t2 values(1,null);
7 select * from #t1 where c2 not in(select c2 from #t2);　　-->执行结果：无
8 select * from #t1 where not exists(select 1 from #t2 where #t2.c2=#t1.c2)　　-->执行结果：1　　3
```
> 1、对于not exists查询，内表存在空值对查询结果没有影响；对于not in查询，内表存在空值将导致最终的查询结果为空。
>
> 2、对于not exists查询，外表存在空值，存在空值的那条记录最终会输出；对于not in查询，外表存在空值，存在空值的那条记录最终将被过滤，其他数据不受影响。


### in,exists问题拓展
#### 1.limit问题
```
-- users表有1000条记录，id自增，id都大于0
-- 下面三条分别输出多少条记录？
select * from users where exists (select * from users limit 0); 
select * from users where exists (select * from users where users.id = 1); 
select * from users where exists (select * from users where id < 0);
```
分别是（选中查看）
<font color=white >10000</font>条，
<font color=white >10000</font>条，
<font color=white >0</font>条。
> exists查询的本质，只要碰到有记录，则返回true；所以limit根本就不会去管，或者说执行不到。

#### 2.exists可以完全代替in吗？
不能。

```
--没有关联字段的情况：枚举常量
select * from areas where id in (4, 5, 6);
--没有关联字段的情况：这样exists对子查询，要么全true，要么全false(文章可能也是转载的，我看不懂他在说啥)
select * from areas where id in (select city_id from deals where deals.name = 'xxx'); 
```
#### exists的sql优化?
1. **用exists替代in**  
使用exists(或not exists)通常将提高查询的效率。 
举例：

```
-- 低效 
select ... from table1 t1 where t1.id > 10 and pno in (select no from table2 where name like 'www%');
-- 高效 
select ... from table1 t1 where t1.id > 10 and exists (select 1 from table2 t2 where t1.pno = t2.no and name like 'www%');
```
2. **用not exists替代not in**  
无论在哪种情况下，**not in都是最低效的** (因为它对子查询中的表执行了一个全表遍历)。 
为了避免使用not in，我们可以把它改写成外连接(Outer Joins)或not exists。
3. **用exists替换distinct**  
当提交一个包含一对多表信息的查询时,避免在select子句中使用distinct. 一般可以考虑用exists替换。  
exists使查询更为迅速,因为RDBMS核心模块将在子查询的条件一旦满足后,立刻返回结果. 
    ``` 
    -- 低效 
    select distinct d.dept_no, d.dept_name from t_dept d, t_emp e where d.dept_no = e.dept_no; 
    -- 高效 
    select d.dept_no, d.dept_name from t_dept d where exists (select 1 from t_emp where d.dept_no = e.dept_no); 
    ```
4.**用表连接替换exists**  
通常来说，采用表连接的方式比exists更有效率。 

    ```
    -- 低效 
    select ename from emp e where exists (select 1 from dept where dept_no = e.dept_no and dept_cat = 'W'); 
    SELECT ENAME 
    -- 高效 
    select ename from dept d, emp e where e.dept_no = d.dept_no and dept_cat = 'W';
    ```



### mysql 的内连接、左连接、右连接
![Sql Joins](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/SQLJoins.png)
- **内连接**:组合两个表中的记录，返回关联字段相符的记录，也就是返回两个表的交集（阴影）部分。
- **左连接**:left join 是left outer join的简写，它的全称是左外连接，是外连接中的一种。 左(外)连接，左表(a_table)的记录将会全部表示出来，而右表(b_table)只会显示符合搜索条件的记录。右表记录不足的地方均为NULL。
- **右连接**: right join是right outer join的简写，它的全称是右外连接，是外连接中的一种。与左(外)连接相反，右(外)连接，左表(a_table)只会显示符合搜索条件的记录，而右表(b_table)的记录将会全部表示出来。左表记录不足的地方均为NULL。




> 参考
> 
> [Mysql—— 内连接、左连接、右连接以及全连接查询](https://blog.csdn.net/zjt980452483/article/details/82945663)  
> [MYSQL中IN与EXISTS的区别](https://www.cnblogs.com/Renyi-Fan/p/10997673.html)  
> [Sql 语句中 IN 和 EXISTS 的区别及应用](https://blog.csdn.net/wqc19920906/article/details/79800374?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param)


---


## 3.1.5 MySQL事务

### ACID
- **A (Atomicity) 原子性**：整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样
- **C (Consistency) 一致性**：在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏
- **I (Isolation)隔离性**：一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰
- **D (Durability) 持久性**：在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚

### 并发事务处理带来的问题
越往上事务隔离级别越低
- **更新丢失**（Lost Update)：事务A和事务B选择同一行，然后基于最初选定的值更新该行时，由于两个事务都不知道彼此的存在，就会发生丢失更新问题
- **脏读**(Dirty Reads)：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据
- **不可重复读**（Non-Repeatable Reads)：事务 A 多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。（MySQL的默认隔离级别能防止以上三个）
- **幻读**（Phantom Reads)：幻读与不可重复读类似。它发生在一个事务A读取了几行数据，接着另一个并发事务B插入了一些数据时。在随后的查询中，事务A就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。


> **幻读和不可重复读的区别：**
>
> **不可重复读的重点是修改**：在同一事务中，同样的条件，第一次读的数据和第二次读的数据不一样。（因为中间有其他事务提交了修改）  
> **幻读的重点在于新增或者删除**：在同一事务中，同样的条件,，第一次和第二次读出来的记录数不一样。（因为中间有其他事务提交了插入/删除）

**解决办法：**
- “更新丢失”通常是应该完全避免的。但防止更新丢失，并不能单靠数据库事务控制器来解决，需要**应用程序**对要更新的数据加必要的锁来解决，因此，防止更新丢失应该是应用的责任。
- “脏读” 、 “不可重复读”和“幻读” ，其实都是数据库读一致性问题，必须由数据库提供一定的**事务隔离机制**来解决：
    -  一种是加锁：在读取数据前，对其加锁，阻止其他事务对数据进行修改。
    - 另一种是**数据多版本并发控制**（MultiVersion Concurrency Control，简称 MVCC（详见下节） 或 MCC），也称为多版本数据库：不用加任何锁， 通过一定机制生成一个数据请求时间点的一致性数据快照 （Snapshot)， 并用这个快照来提供一定级别 （语句级或事务级） 的一致性读取。从用户的角度来看，好象是数据库可以提供同一数据的多个版本。


### 事务隔离级别
查看当前数据库的事务隔离级别：

```
show variables like 'tx_isolation';
--或者
SELECT @@tx_isolation;
```
![默认事务](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/QQ%E5%9B%BE%E7%89%8720200720114359.png)

事务隔离级别由低到高为：

- **READ-UNCOMMITTED(读未提交)**： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。
- **READ-COMMITTED(读已提交)**： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。
- **REPEATABLE-READ(可重复读)**： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。（MySQL默认隔离级别）
- **SERIALIZABLE(可串行化)**： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。
 
> 数据库的事务隔离越严格，并发副作用越小，但付出的代价就越大，因为事务隔离实质上就是使事务在一定程度上“串行化”进行，这显然与“并发”是矛盾的。同时，不同的应用对读一致性和事务隔离程度的要求也是不同的，比如许多应用对“不可重复读”和“幻读”并不敏感，可能更关心数据并发访问的能力。

#### 理解
**Read uncommitted**  
读未提交，就是一个事务可以读取另一个未提交事务的数据。

事例：老板要给程序员发工资，程序员的工资是3.6万/月（酸了）。但是发工资时老板不小心按错了数字，按成3.9万/月，该钱已经打到程序员的户口，但是事务还没有提交，就在这时，程序员去查看自己这个月的工资，发现比往常多了3千元，以为涨工资了非常高兴。但是老板及时发现了不对，马上回滚差点就提交了的事务，将数字改成3.6万再提交。

分析：实际程序员这个月的工资还是3.6万，但是程序员看到的是3.9万。他看到的是老板还没提交事务时的数据。这就是**脏读**（程序员脸上笑嘻嘻）。

那怎么解决脏读呢？Read committed！读提交，能解决脏读问题。

**Read committed**

读提交，顾名思义，就是一个事务要等另一个事务提交后才能读取数据。

事例：程序员拿着信用卡去享受生活（卡里当然是只有3.6万），当他买单时（程序员事务开启），收费系统事先检测到他的卡里有3.6万，就在这个时候！！程序员的妻子要把钱全部转出充当家用，并提交。当收费系统准备扣款时，再检测卡里的金额，发现已经没钱了（第二次检测金额当然要等待妻子转出金额事务提交完）。程序员就会很郁闷，明明卡里是有钱的…

分析：这就是读提交，若有事务对数据进行更新（UPDATE）操作时，读操作事务要等待这个更新操作事务提交后才能读取数据，可以解决脏读问题。但在这个事例中，出现了一个事务范围内两个相同的查询却返回了不同数据，这就是**不可重复读**。

那怎么解决可能的不可重复读问题？Repeatable read ！

**Repeatable read**

**重复读，就是在开始读取数据（事务开启）时，不再允许修改操作。MySQL的默认事务隔离级别**

事例：程序员拿着信用卡去享受生活（卡里当然是只有3.6万），当他埋单时（事务开启，不允许其他事务的UPDATE修改操作），收费系统事先检测到他的卡里有3.6万。这个时候他的妻子不能转出金额了。接下来收费系统就可以扣款了。

分析：重复读可以解决不可重复读问题。写到这里，应该明白的一点就是，不可重复读对应的是修改，即**UPDATE**操作。但是可能还会有幻读问题。因为幻读问题对应的是插入INSERT操作，而不是UPDATE操作。

**幻读**：
事例：程序员某一天去消费，花了2千元，然后他的妻子去查看他今天的消费记录（全表扫描FTS，妻子事务开启），看到确实是花了2千元，就在这个时候，程序员花了1万买了一部电脑，即新增INSERT了一条消费记录，并提交。当妻子打印程序员的消费记录清单时（妻子事务提交），发现花了1.2万元，似乎出现了幻觉，这就是幻读。

那怎么解决幻读问题？Serializable！

**Serializable 序列化**

Serializable 是最高的事务隔离级别，在该级别下，事务串行化顺序执行，可以避免脏读、不可重复读与幻读。简单来说，**Serializable会在读取的每一行数据上都加锁，所以可能导致大量的超时和锁争用问题。这种事务隔离级别效率低下，比较耗数据库性能，一般不使用。**


事务隔离级别 |读数据一致性| 脏读 | 不可重复读 | 幻读 
---|---|---|---|---
读未提交（read-uncommitted） | 最低级别，只能保证不读取物理上损坏的数据 | 是 | 是 | 是
读已提交（read-committed） | 语句级 | 否 | 是 | 是
可重复读（repeatable-read）| 事务级 | 否 | 否 | 是
串行化（serializable）| 最高级别，事务级 | 否 | 否 | 否

> 事务隔离级别和数据访问的并发性是对立的，**事务隔离级别越高并发性就越差**。所以要根据具体的应用来确定合适的事务隔离级别，这个地方没有万能的原则。

与 SQL 标准不同的地方在于InnoDB 存储引擎在 REPEATABLE-READ（可重读）事务隔离级别下使用的是**Next-Key Lock** 算法，因此可以避免幻读的产生，这与其他数据库系统(如 SQL Server)是不同的。**所以说InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ**(可重读)，已经可以完全保证事务的隔离性要求，即达到了 SQL标准的 SERIALIZABLE(可串行化)隔离级别，而且保留了比较好的并发性能。

大部分数据库（oracle，sql server）默认事务隔离级别是**READ-COMMITTED**(读已提交)，但MySQL默认是**REPEATABLE-READ**（可重读）并不会有任何性能损失。


### MVCC
MultiVersion Concurrency Control：多版本并发控制。
大多数事务型存储引擎实现都不是简单的行级锁。基于提升并发性考虑，一般都同时实现了多版本并发控制（MVCC），包括Oracle、PostgreSQL。只是实现机制各不相同。

可以认为 MVCC 是行级锁的一个变种，但它在很多情况下避免了加锁操作，因此开销更低。虽然实现机制有所不同，但大都实现了非阻塞的读操作，写操作也只是锁定必要的行。

**基本原理**

**MVCC 的实现是通过保存数据在某个时间点的快照来实现的**。也就是说不管需要执行多长时间，每个事物看到的数据都是一致的。

典型的MVCC实现方式，分为**乐观（optimistic）并发控制**和**悲观（pressimistic）并发控制**。


#### InnoDB存储引擎MVCC的实现

InnoDB 的 MVCC，是通过在每行记录后**面保存两个隐藏的列**来实现。这两个列，一个保存了行的创建时间，一个保存行的过期时间（删除时间）。当然存储的并不是真实的时间，而是系统版本号（system version number）。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。  
每个事务又有自己的版本号，这样事务内执行CRUD操作时，就通过版本号的比较来达到数据版本控制的目的。


1. **Insert**：记录的版本号即当前事务的版本号。  
执行一条数据语句：`insert into testmvcc values(1,"test");`
假设事务id为1，那么插入后的数据行如下：  
![1](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/1536286392011332dc79980.jpg)

2. **Update**:先标记旧的那行记录为已删除，并且删除版本号是事务版本号，然后插入一行新的记录的方式。  
比如，针对上面那行记录，事务Id为2 要把name字段更新
`update table set name= 'new_value' where id=1;`  
![2](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/15362864790262a85896e55.jpg)

3. **delete**：把事务版本号作为删除版本号。
`delete from table where id=1;`  
![3](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/15362865324150dfbc7bf66.jpg)

4. **Select**:
从上面的描述可以看到，在查询时要符合以下两个条件的记录才能被事务查询出来：

  - **删除版本号未指定或者大于当前事务版本号**，即查询事务开启后确保读取的行未被删除。(即上述事务id为2的事务查询时，依然能读取到事务id为3所删除的数据行)
  - **创建版本号 小于或者等于 当前事务版本号** ，就是说记录创建是在当前事务中（等于的情况）或者在当前事务启动之前的其他事物进行的insert。
（即事务id为2的事务只能读取到create version<=2的已提交的事务的数据集）

保存这两个额外系统版本号，使大多数操作都不用加锁。使数据操作简单，性能很好，并且也能保证只会读取到符合要求的行。不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作和一些额外的维护工作。

> **注意**
>
>1. MVCC手段只适用于Msyql隔离级别中的读已提交（Read committed）和可重复读（Repeatable Read）
>2. Read uncommitted由于存在脏读，即能读到未提交事务的数据行，所以不适用MVCC.原因是MVCC的创建版本和删除版本只要在事务提交后才会产生。
>3. 串行化由于是会对所涉及到的表加锁，并非行锁，自然也就不存在行的版本控制问题。
>4. 通过以上总结，可知，MVCC主要作用于事务性的，有行锁控制的数据库模型。

### 事务日志
事务的隔离性是通过锁实现，而事务的原子性、一致性和持久性则是通过**事务日志**实现 。

> - 使用事务日志，存储引擎在修改表的数据时只需要修改其内存拷贝，再把该修改行为记录到持久在硬盘上的事务日志中，而不用每次都将修改的数据本身持久到磁盘。  
> - 事务日志采用的是追加的方式，因此写日志的操作是磁盘上一小块区域内的顺序I/O，而不像随机I/O需要在磁盘的多个地方移动磁头，所以采用事务日志的方式相对来说要快得多。  
> - 事务日志持久以后，内存中被修改的数据在后台可以慢慢刷回到磁盘。  
> - 如果数据的修改已经记录到事务日志并持久化，但数据本身没有写回到磁盘，此时系统崩溃，存储引擎在重启时能够自动恢复这一部分修改的数据。

MySQL 中支持事务的存储引擎有 InnoDB 和 NDB。这里以InnoDB引擎分析。

**redo log（重做日志）** 实现持久化和原子性

在InnoDB的存储引擎中，事务日志通过重做(redo)日志和InnoDB存储引擎的日志缓冲(InnoDB Log Buffer)实现。事务开启时，事务中的操作，都会先写入存储引擎的日志缓冲中，在事务提交之前，这些缓冲的日志都需要提前刷新到磁盘上持久化，这就是DBA们口中常说的“日志先行”(Write-Ahead Logging)。当事务提交之后，在Buffer Pool中映射的数据文件才会慢慢刷新到磁盘。此时如果数据库崩溃或者宕机，那么当系统**重启进行恢复时，就可以根据redo log中记录的日志**，把数据库恢复到崩溃前的一个状态。未完成的事务，可以继续提交，也可以选择回滚，这基于恢复的策略而定。

在系统启动的时候，就已经为redo log分配了一块连续的存储空间，以顺序追加的方式记录Redo Log，通过顺序IO来改善性能。所有的事务共享redo log的存储空间，它们的Redo Log按语句的执行顺序，依次交替的记录在一起。

**undo log（回滚日志**）  实现一致性

undo log 主要为事务的回滚服务。在事务执行的过程中，除了记录redo log，还会记录一定量的undo log。undo log记录了数据在每个操作前的状态，如果事务执行过程中需要回滚，就可以根据undo log进行回滚操作。单个事务的回滚，只会回滚当前事务做的操作，并不会影响到其他的事务做的操作。

Undo记录的是已部分完成并且写入硬盘的未完成的事务，默认情况下回滚日志是记录下表空间中的（共享表空间或者独享表空间）
> 二种日志均可以视为一种恢复操作，redo_log是恢复提交事务修改的页操作，而undo_log是回滚行记录到特定版本。二者记录的内容也不同，redo_log是物理日志，记录页的物理修改操作，而undo_log是逻辑日志，根据每行记录进行记录。


> **你知道MySQL 有多少种日志吗？**
> 
> - **错误日志**：记录出错信息，也记录一些警告信息或者正确的信息。
> - **查询日志**：记录所有对数据库请求的信息，不论这些请求是否得到了正确的执行。
> - **慢查询日志**：设置一个阈值，将运行时间超过该值的所有SQL语句都记录到慢查询的日志文件中。
> - **二进制日志**：记录对数据库执行更改的所有操作。
> - **中继日志**：中继日志也是二进制日志，用来给slave 库恢复
> - **事务日志**：重做日志redo和回滚日志undo

### MySQL对分布式事务的支持
分布式事务的实现方式有很多，既可以采用 InnoDB 提供的原生的事务支持，也可以采用消息队列来实现分布式事务的最终一致性。这里我们主要聊一下 InnoDB 对分布式事务的支持。

MySQL 从 5.0.3  InnoDB 存储引擎开始支持XA(2PC)协议的分布式事务。一个分布式事务会涉及多个行动，这些行动本身是事务性的。所有行动都必须一起成功完成，或者一起被回滚。

在MySQL中，使用分布式事务涉及一个或多个资源管理器和一个事务管理器。

MySQL 的分布式事务模型。模型中分三块：应用程序（AP）、资源管理器（RM）、事务管理器（TM）:

- 应用程序：定义了事务的边界，指定需要做哪些事务；
- 资源管理器：提供了访问事务的方法，通常一个数据库就是一个资源管理器；
- 事务管理器：协调参与了全局事务中的各个事务。

分布式事务采用两段式提交（two-phase commit）的方式：

- 第一阶段所有的事务节点开始准备，告诉事务管理器ready。
- 第二阶段事务管理器告诉每个节点是commit还是rollback。如果有一个节点失败，就需要全局的节点全部rollback，以此保障事务的原子性。

一个基于2PC的事务

![一个基于2PC的事务](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/20170417115753356.jpg)

> **参考**
>
>[Mysql中MVCC的使用及原理详解](https://blog.csdn.net/w2064004678/article/details/83012387)
>
>[以交易系统为例，看分布式事务架构的五大演进](https://blog.csdn.net/w05980598/article/details/79305239)



---

## 3.1.6 MySQL锁

### 锁的分类
![MySQL锁](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/164c6d7ae44d8ac6.png)

**从对数据操作的类型分类：**

- 读锁（共享锁）：针对同一份数据，多个读操作可以同时进行，不会互相影响
- 写锁（排他锁）：当前写操作没有完成前，它会阻断其他写锁和读锁

**从对数据操作的粒度分类**：

为了尽可能提高数据库的并发度，每次锁定的数据范围越小越好，理论上每次只锁定当前操作的数据的方案会得到最大的并发度，但是管理锁是很耗资源的事情（涉及获取，检查，释放锁等动作），因此数据库系统需要在高并发响应和系统性能两方面进行平衡，这样就产生了“锁粒度（Lock granularity）”的概念。

- 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低（MyISAM 和 MEMORY 存储引擎采用的是表级锁）；

- 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高（InnoDB 存储引擎既支持行级锁也支持表级锁，但默认情况下是采用行级锁）；

- 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。



引擎 | 行锁 | 表锁 | 页锁
---|---|---|---
MyISAM |   | √ |   |
BDB    |   | √ | √ |
InnoDB | √ | √ |   |
Memory |   | √ |   |



**按使用方式**：
- 悲观锁
- 乐观锁


### 共享锁和排他锁
**共享锁**(Share Lock)又称读锁，是读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行修改（获取数据上的排他锁），直到已释放所有共享锁。

如果事务T对数据A加上共享锁后，则其他事务只能对A再加共享锁，不能加排他锁。获准共享锁的事务只能读数据，不能修改数据。
用法
```
SELECT ... LOCK IN SHARE MODE;
```
在查询语句后面增加`LOCK IN SHARE MODE`，MySQL会对查询结果中的每行都加共享锁，当没有其他线程对查询结果集中的任何一行使用排他锁时，可以成功申请共享锁，否则会被阻塞。其他线程也可以读取使用了共享锁的表，而且这些线程读取的是同一个版本的数据。

**排他锁**（eXclusive Lock）又称写锁，如果事务T对数据A加上排他锁后，则其他事务不能再对A加任任何类型的封锁。获准排他锁的事务既能读数据，又能修改数据。
```
SELECT ... FOR UPDATE;
```
在查询语句后面增加FOR UPDATE，Mysql会对查询结果中的每行都加排他锁，当没有其他线程对查询结果集中的任何一行使用排他锁时，可以成功申请排他锁，否则会被阻塞。

> 对于UPDATE、DELETE、INSERT语句，InnoDB会自动给涉及数据集加**排他锁**（X)
> **注意InnoDB不会为普通select加读锁！**
>
> MyISAM在执行查询语句SELECT前，会自动给涉及的所有表加**读锁**，在执行更新操作（UPDATE、DELETE、INSERT等）前，会自动给涉及的表加**写锁**，这个过程并不需要用户干预

### 表锁与行锁
**表锁**：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突概率高，并发度最低。

**行锁**：开销大，加锁慢；会出现死锁；锁定粒度小，发生锁冲突的概率低，并发度高

> - **InnoDB行锁和表锁都支持！**  
> - **MyISAM只支持表锁！**  
> - InnoDB只有通过**索引**条件检索数据才使用行级锁，否则，InnoDB将使用表锁,也就是说，**InnoDB的行锁是基于索引的!**

#### 表锁
**MyISAM** 的表锁有两种模式：

- 表共享读锁 （Table Read Lock）：不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；
- 表独占写锁 （Table Write Lock）：会阻塞其他用户对同一表的读和写操作；

MyISAM 表的读操作与写操作之间，以及写操作之间是串行的。当一个线程获得对一个表的写锁后， 只有持有锁的线程可以对表进行更新操作。其他线程的读、 写操作都会等待，直到锁被释放为止。

默认情况下，**写锁比读锁具有更高的优先级**：当一个锁释放时，这个锁会优先给写锁队列中等候的获取锁请求，然后再给读锁队列中等候的获取锁请求。

为了允许行锁和表锁共存，实现多粒度锁机制，**InnoDB**还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是**表锁**：

- 意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。
- 意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。

> 意向锁是数据库隐式帮我们做了，不需要程序员操心！
> 其实意向锁就只是一个标识，如果给某一数据行加了排他锁，那么它之前也加了IX锁，别的事务这时想锁表，就只用看看IX锁有没有，如果有，就等待，而不用去遍历每一行数据查看是否有排他锁。

我们是**很少手动加表锁**的。表锁对我们程序员来说几乎是透明的，即使InnoDB不走索引，**加的表锁也是自动的**！
> **注意 InnoDb中RC级别不走索引也是不会锁表的，只会该加锁的行加行锁！**  

我们应该更加关注行锁的内容，因为InnoDB一大特性就是支持行锁。

#### 行锁
InnoDB实现了以下两种类型的行锁。

- **共享锁**（S锁）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。  
也叫做读锁：读锁是共享的，多个客户可以同时读取同一个资源，但不允许其他客户修改。


- **排他锁**（X锁)：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。  
也叫做写锁：写锁是排他的，写锁会阻塞其他的写锁和读锁。

上面说到**InnoDB的行锁是基于索引的**，这里举例说明一下。

假设有个表单 products ，里面有id跟name二个栏位，id是主键。
```
-- 明确指定主键，并且有此笔资料，row lock
SELECT * FROM products WHERE id='3' FOR UPDATE;
SELECT * FROM products WHERE id='3' and type=1 FOR UPDATE;
```
```
-- 明确指定主键，若查无此笔资料，无lock
SELECT * FROM products WHERE id='-1' FOR UPDATE;
```
```
-- 无主键，table lock
SELECT * FROM products WHERE name='Mouse' FOR UPDATE;
```
```
-- 主键不明确，table lock
SELECT * FROM products WHERE id<>'3' FOR UPDATE;
SELECT * FROM products WHERE id LIKE '3' FOR UPDATE;
```
再来一个例子：

> 假设我们有一张消息表（msg），里面有3个字段。假设id是主键，token是非唯一索引，message没有索引。

innodb对于主键使用了聚簇索引，这是一种数据存储方式，表数据是和主键一起存储，主键索引的叶结点存储行数据。对于普通索引，其叶子节点存储的是主键值。(之前也讲过了)  
![1](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/bdc940fef6f0c3bf2c7277f2614bd0d2e5563124.png)

1. `delete from msg where id=2；`  
由于id是主键，因此直接锁住整行记录即可。  
![2](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/2f67547e0caa0d1ea9bc7cb53966eedf70d49db3.png)

2. `delete from msg where token=’ cvs’;`   
由于token是二级索引，因此首先锁住二级索引（两行），接着会锁住相应主键所对应的记录；  
![3](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/e0ac34fd99404ccdee4ab1ec4889f47754ffcd82.png)

3. `delete from msg where message=订单号是多少’；`  
message没有索引，所以走的是全表扫描过滤。这时表上的各个记录都将添加上X锁。  
![4](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/aa9a94c735ec35cfe92cd5eca1015893aad8de58.png)

### 悲观锁与乐观锁

#### 悲观锁
悲观锁会“悲观地”假定大概率会发生并发更新冲突，访问、处理数据前就加排他锁，在整个数据处理过程中锁定数据，事务提交或回滚后才释放锁。另外与乐观锁相对应的，悲观锁是由数据库自己实现了的，要用的时候，我们直接调用数据库的相关语句就可以了。
```
select * from xxxx for update
```
在`select` 语句后边加了 `for update`相当于加了**排它锁**(写锁)，加了写锁以后，其他的事务就不能对它修改了！需要等待当前事务修改完之后才可以修改.
> MySQL有个问题是select...for update语句执行中所有扫描过的行都会被锁上，因此在MySQL中用悲观锁务必须确定走了**索引**，而不是全表扫描，否则将会将整个数据表锁住。
> 
> 在Oracle中，也存在select ... for update，和mysql一样，但是Oracle还存在了select ... for update nowait，即发现被锁后不等待，立刻报错。
>
>**for update仅适用于InnoDB,且必须在事务块(BEGIN/COMMIT)中才能生效**

#### 乐观锁

乐观锁会“乐观地”假定大概率不会发生并发更新冲突，访问、处理数据过程中不加锁，只在更新数据时再根据版本号或时间戳判断是否有冲突，有则处理，无则提交事务。用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。

乐观锁相对悲观锁而言，它认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回错误信息，让用户决定如何去做。

利用**数据版本号**（version）机制是乐观锁最常用的一种实现方式，另一种是通过时间戳。一般通过为数据库表增加一个数字类型的 “version” 字段，当读取数据时，将version字段的值一同读出，**数据每更新一次，对此version值+1**。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与**第一次取出来的version**值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据，返回更新失败。  
![乐观锁](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/4461377-d7472568e615e335.png)

```
-- step1: 查询出商品信息
select (quantity,version) from items where id=100;
-- step2: 根据商品信息生成订单
insert into orders(id,item_id) values(null,100);
-- step3: 修改商品的库存（此version就是第一步查出来的version，如果不一致，说明其它线程已经更改，则更新失败。）
update items set quantity=quantity-1,version=version+1 where id=100 and version=#{version};
```
使用时间戳字段类似，该方法同样是在表中增加一个时间戳字段，和上面的version类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。

> 如果数据表是读写分离的表，当master表中写入的数据没有及时同步到slave表中时会造成更新一直失败的问题。此时，需要强制读取master表中的数据（**将select语句放在事务中**）。  
> 把select语句放在事务中，查询的就是master主库了


商品库存扣减时，尤其是在秒杀、聚划算这种高并发的场景下，若采用version号作为乐观锁，则每次只有一个事务能更新成功，业务感知上就是大量操作失败。此时可以挑选库存数作为乐观锁
```
//step1: 查询出商品信息
select (inventory) from items where id=100;
//step2: 根据商品信息生成订单
insert into orders(id,item_id) values(null,100);
//step3: 修改商品的库存
update items set inventory=inventory-1 where id=100 and inventory-1>0;
```
> 现在互联网高并发的架构中，受到fail-fast思路的影响，悲观锁已经非常少见了。

#### 拓展
在阿里很多系统中都能看到常用的features、params等字段，这些字段如果不进行版本控制，在并发场景下非常容易出现信息覆盖的问题。  
但如果利用全局字段version进行处理，则会发现与表中的其他字段变更有非常高的冲突率，因为version字段是全局的。有可能是修改不同字段，但是verision都会更改。所以会添加对应的版本控制字段，例如`features_cc`
```
update    
    lg_order
set    
    features=#features#,    
    features_cc= features_cc +1
where    
    order_id=#order_id#    
    and features_cc =#ori_ features_cc#
```
不过做这种字段的精耕细作控制，是以**提高维护成本**作为代价的。

### InnoDB三种行锁的算法
#### 记录锁(Record Locks)
单个行记录上的锁。对索引项加锁，锁定符合条件的行。其他事务不能修改和删除加锁项；
```
-- 它会在 id=1 的记录上加上记录锁，以阻止其他事务插入，更新，删除 id=1 这一行
SELECT * FROM table WHERE id = 1 FOR UPDATE;
-- 在通过 主键索引 与 唯一索引 对数据行进行 UPDATE 操作时，也会对该行数据加记录锁：
-- id 列为主键列或唯一索引列
UPDATE SET age = 50 WHERE id = 1;
```
#### 间隙锁（Gap Locks）
当我们使用**范围条件**而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁。对于键值在条件范围内但并不存在的记录，叫做“间隙”。

InnoDB 也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁。

对索引项之间的“间隙”加锁，锁定记录的范围（对第一条记录前的间隙或最后一条将记录后的间隙加锁），不包含索引项本身。其他事务不能在锁范围内插入数据，这样就防止了别的事务新增幻影行。

间隙锁基于非唯一索引，它锁定一段范围内的索引记录。间隙锁基于下面将会提到的Next-Key Locking 算法，请务必牢记：**使用间隙锁锁住的是一个区间，而不仅仅是这个区间中的每一条数据**。
```
/* 所有在（1，10）区间内的记录行都会被锁住，
 所有id 为 2、3、4、5、6、7、8、9 的数据行的插入会被阻塞，
 但是 1 和 10 两条记录行并不会被锁住。*/
SELECT * FROM table WHERE id BETWEN 1 AND 10 FOR UPDATE;
```
> GAP锁的目的，是为了防止同一事务的两次当前读，出现**幻读**的情况

#### 临键锁(Next-key Locks)
临键锁，是**记录锁与间隙锁的组合**，它的封锁范围，既包含索引记录，又包含索引区间。(**临键锁的主要目的，也是为了避免幻读**(Phantom Read)。如果把事务的隔离级别降级为READ-COMMITTED，临键锁则也会失效。)

Next-Key 可以理解为一种特殊的间隙锁，也可以理解为一种特殊的算法。通过临建锁可以解决幻读的问题。每个数据行上的非唯一索引列上都会存在一把临键锁，当某个事务持有该数据行的临键锁时，会锁住一段左开右闭区间的数据。需要强调的一点是，InnoDB 中行级锁是基于索引实现的，**临键锁只与非唯一索引列**有关，在唯一索引列（包括主键列）上不存在临键锁。

对于行的查询，都是采用该方法，主要目的是解决幻读的问题。

> 在RR隔离级别下(InnoDB默认)，Innodb对于行的扫描锁定都是使用此算法，但是如果查询扫描中有唯一索引会退化成只使用**记录锁**。
> 
> 要说明的是如果有间隙锁了，插入意向锁会被阻塞。所以能防止幻读(**但可能造成死锁！**)

### 死锁
死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环。  
当事务试图以不同的顺序锁定资源时，就可能产生死锁。多个事务同时锁定同一个资源时也可能会产生死锁。  
锁的行为和顺序和存储引擎相关。以同样的顺序执行语句，有些存储引擎会产生死锁有些不会——死锁有双重原因：真正的数据冲突；存储引擎的实现方式。

#### 死锁成因
1. **不同表相同记录行锁冲突**  
事务A和事务B操作两张表，但出现循环等待锁情况。  
![不同表相同记录行锁冲突](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/da89a5774d02b974b63bf08bf47f146c94e75909.png)

2. **相同表记录行锁冲突**  
事务A和事务B操作一张表，A处理的id为1、2，B处理的id为2、1。  
![相同表记录行锁冲突](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/e470063b82bb3d005f6935cb51ec656c2c1a3d1e.png)

3. **不同索引锁冲突**  
这种情况比较隐晦，事务A在执行时，除了在二级索引加锁外，还会在聚簇索引上加锁，在聚簇索引上加锁的顺序是[1,4,2,3,5]，而事务B执行时，只在聚簇索引上加锁，加锁顺序是[1,2,3,4,5]，这样就造成了死锁的可能性。  
![不同索引锁冲突](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/39f0c70708ebb31acaea725bb9b712f780298bdd.png)

3. **gap锁冲突**  
 innodb在RR级别下，如下的情况也会产生死锁，比较隐晦。就是之前说的，RR能防止幻读，但**可能造成死锁**。主要就是间隙锁导致**插入意向锁会被阻塞**。  
![gap锁冲突](https://sunsasdoc.oss-cn-hangzhou.aliyuncs.com/image/cedf457ff5099ef54643ab17d21d041333e74943.png)

#### 检测死锁
数据库系统实现了各种死锁检测和死锁超时的机制。InnoDB存储引擎能检测到死锁的循环依赖并立即返回一个错误。  
但在涉及外部锁，或涉及表锁的情况下，InnoDB 并不能完全自动检测到死锁， 这需要通过设置锁等待超时参数 innodb_lock_wait_timeout 来解决。

如果出现死锁，可以用 `show engine innodb status;`命令来确定最后一个死锁产生的原因。返回结果中包括死锁相关事务的详细信息，如引发死锁的 SQL 语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等。据此可以分析死锁产生的原因和改进措施。

#### 死锁恢复
死锁发生以后，只有部分或完全回滚其中一个事务，才能打破死锁，InnoDB目前处理死锁的方法是，**将持有最少行级排他锁的事务进行回滚**。所以事务型应用程序在设计时必须考虑如何处理死锁，多数情况下只需要重新执行因死锁回滚的事务即可。

死锁会影响性能而不是会产生严重错误，因为InnoDB会自动检测死锁状况并回滚其中一个受影响的事务。在高并发系统上，当许多线程等待同一个锁时，死锁检测可能导致速度变慢。有时当发生死锁时，禁用死锁检测（使用innodb_deadlock_detect配置选项）可能会更有效，这时可以依赖innodb_lock_wait_timeout设置进行事务回滚。

#### 如何避免死锁
在自动加锁的情况下，MyISAM 总是一次获得 SQL 语句所需要的全部锁，所以 MyISAM 表不会出现死锁。

- 如果事务需要修改或锁定多个表，则应在每个事务中以相同的顺序使用加锁语句。在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会
- 大事务拆小。大事务更倾向于死锁，如果业务允许，将大事务拆小。
- 在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应先申请共享锁、更新时再申请排他锁，因为这时候当用户再申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁。
- 在同一个事务中，尽可能做到一次锁定所需要的**所有资源**，减少死锁概率。
- 为了在单个InnoDB表上执行多个并发写入操作时避免死锁，可以在事务开始时通过为预期要修改的每个元祖（行）使用SELECT ... FOR UPDATE语句来**获取必要的锁**，即使这些行的更改语句是在之后才执行的。
- **降低隔离级别**。如果业务允许，将隔离级别调低也是较好的选择，比如将隔离级别从RR调整为RC，可以避免掉很多因为gap锁造成的死锁。
- **为表添加合理的索引**。可以看到如果不走索引将会为表的每一行记录添加上锁，死锁的概率大大增大。


> 参考
> 
> [探索Mysql锁机制(一)——乐观锁&悲观锁](https://www.jianshu.com/p/ed896335b3b4)  
> [MySQL中的共享锁与排他锁](http://www.hollischuang.com/archives/923)  
> [数据库两大神器【索引和锁】](https://juejin.im/post/5b55b842f265da0f9e589e79#heading-13)  
> [mysql死锁问题分析](https://www.cnblogs.com/LBSer/p/5183300.html)  
> [为什么开发人员必须要了解数据库锁？](https://mp.weixin.qq.com/s/yzXbbutzVJ1hIZgVszIBgw)